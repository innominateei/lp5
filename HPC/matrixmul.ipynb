{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85bceb4b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#include<stdio.h>\n",
    "__global__ void matmul(float *A, float *B, float *C, int N){\n",
    "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
    "    int col = blockIdx.x * blockIdx.x + threadIdx.x;\n",
    "    if (row < N  && col < N){\n",
    "        float sum = 0;\n",
    "        for (int k = 0; k < N ; k++)\n",
    "            sum += A[row*N + k] * B[k*N + col];\n",
    "        C[row*N + col] = sum;\n",
    "\n",
    "    }\n",
    "}\n",
    "\n",
    "int main(){\n",
    "    int N = 2;\n",
    "    size_t size = N*N * sizeof(float);\n",
    "    float A[] = {1, 2, 3, 4};\n",
    "    float B[] = {5, 6, 7, 8};\n",
    "    float C[4];\n",
    "\n",
    "    float *d_A, *d_B, *d_C;\n",
    "    cudaMalloc(&d_A, size);\n",
    "    cudaMalloc(&d_B, size);\n",
    "    cudaMalloc(&d_C, size);\n",
    "\n",
    "    cudaMemcpy(d_A, A, size, cudaMemcpyHostToDevice);\n",
    "    cudaMemcpy(d_B, B, size, cudaMemcpyHostToDevice);\n",
    "\n",
    "    dim3 threads(16,16);\n",
    "    dim3 blocks((N+15)/16, (N+15)/16);\n",
    "    matmul<<<blocks, threads>>>(d_A, d_B, d_C, N);\n",
    "\n",
    "    cudaMemcpy(C, d_C, size, cudaMemcpyDeviceToHost);\n",
    "\n",
    "    printf(\"Result Matrix C:\\n\");\n",
    "    for (int i = 0; i < N*N; i++){\n",
    "        printf(\"%f \", C[i]);\n",
    "        if((i+1)%N == 0) printf(\"\\n\");\n",
    "\n",
    "    }\n",
    "\n",
    "     cudaFree(d_A);\n",
    "     cudaFree(d_B);\n",
    "     cudaFree(d_C);\n",
    "     return 0;\n",
    "\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
